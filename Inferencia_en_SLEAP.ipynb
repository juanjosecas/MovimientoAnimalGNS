{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Inferencia en SLEAP\n",
                "\n",
                "Este notebook realiza el análisis de video utilizando DeepLabCut para el seguimiento de movimiento animal.\n",
                "\n",
                "## Pasos del proceso:\n",
                "1. Importación de librerías necesarias\n",
                "2. Carga y verificación del archivo de configuración\n",
                "3. Análisis de propiedades del video\n",
                "4. Recorte del video a una región de interés (ROI)\n",
                "5. Análisis del video con DeepLabCut\n",
                "6. Filtrado de predicciones\n",
                "7. Creación de video con etiquetas"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Importación de librerías\n",
                "\n",
                "Importamos las librerías necesarias para el procesamiento de video y análisis con DeepLabCut."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import deeplabcut as dlc\n",
                "import cv2\n",
                "import numpy as np\n",
                "import os\n",
                "import sys\n",
                "import yaml\n",
                "import matplotlib.pyplot as plt\n",
                "import time\n",
                "\n",
                "print('Importación de módulos completada')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Carga del archivo de configuración\n",
                "\n",
                "Cargamos el archivo de configuración de SLEAP/DeepLabCut y verificamos que todos los directorios necesarios existan."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ruta al archivo de configuración\n",
                "path_config_file = 'Experimento Olfato-JJ-2024-02-19/config2.yaml'\n",
                "\n",
                "# Verificamos que el archivo de configuración exista\n",
                "if not os.path.exists(path_config_file):\n",
                "    print(f'ERROR: No existe el archivo de configuración en {path_config_file}')\n",
                "    sys.exit(1)\n",
                "\n",
                "print(f'Archivo de configuración encontrado: {path_config_file}')\n",
                "\n",
                "# Cargamos el contenido del archivo de configuración\n",
                "with open(path_config_file, 'r') as file:\n",
                "    config = yaml.safe_load(file)\n",
                "\n",
                "print('\\nContenido de la configuración:')\n",
                "print(config)\n",
                "\n",
                "# Verificamos que el directorio del proyecto exista\n",
                "project_path = config.get('project_path', '')\n",
                "if not project_path:\n",
                "    print('\\nERROR: No se encontró project_path en la configuración')\n",
                "    sys.exit(1)\n",
                "\n",
                "if not os.path.exists(project_path):\n",
                "    print(f'\\nERROR: El directorio del proyecto no existe: {project_path}')\n",
                "    sys.exit(1)\n",
                "\n",
                "print(f'\\nDirectorio del proyecto verificado: {project_path}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Análisis de propiedades del video\n",
                "\n",
                "Cargamos el video y extraemos sus propiedades principales (fps, número de frames, dimensiones, etc.).\n",
                "También visualizamos un frame aleatorio para verificar que el video se cargó correctamente."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ruta al video de entrada\n",
                "video_path = 'experiments/A-7.mp4'\n",
                "\n",
                "# Verificamos que el archivo de video exista\n",
                "if not os.path.exists(video_path):\n",
                "    print(f'ERROR: No existe el archivo de video en {video_path}')\n",
                "    sys.exit(1)\n",
                "\n",
                "print(f'Archivo de video encontrado: {video_path}')\n",
                "\n",
                "# Abrimos el video para analizar sus propiedades\n",
                "cap = cv2.VideoCapture(video_path)\n",
                "\n",
                "# Verificamos que el video se haya abierto correctamente\n",
                "if not cap.isOpened():\n",
                "    print('ERROR: Error al abrir el video')\n",
                "    sys.exit(1)\n",
                "\n",
                "# Intentamos leer el primer frame\n",
                "ret, frame = cap.read()\n",
                "if not ret:\n",
                "    print('ERROR: No se pudo leer el primer frame del video')\n",
                "    cap.release()\n",
                "    sys.exit(1)\n",
                "\n",
                "print('Video abierto correctamente')\n",
                "\n",
                "# Extraemos las propiedades básicas del video\n",
                "fps = cap.get(cv2.CAP_PROP_FPS)\n",
                "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
                "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
                "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
                "fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
                "\n",
                "# Mostramos la información del video\n",
                "print(f'\\nPropiedades del video:')\n",
                "print(f'  Frames por segundo (FPS): {fps}')\n",
                "print(f'  Total de frames: {total_frames}')\n",
                "print(f'  Ancho: {width} píxeles')\n",
                "print(f'  Alto: {height} píxeles')\n",
                "print(f'  Codec (FOURCC): {fourcc}')\n",
                "\n",
                "# Seleccionamos un frame aleatorio para visualizar\n",
                "random_frame_number = np.random.randint(0, total_frames)\n",
                "cap.set(cv2.CAP_PROP_POS_FRAMES, random_frame_number)\n",
                "ret, random_frame = cap.read()\n",
                "\n",
                "# Mostramos el frame seleccionado\n",
                "if ret:\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    frame_rgb = cv2.cvtColor(random_frame, cv2.COLOR_BGR2RGB)\n",
                "    plt.imshow(frame_rgb)\n",
                "    plt.axis('off')\n",
                "    plt.title(f'Frame aleatorio #{random_frame_number}')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print(f'ADVERTENCIA: No se pudo leer el frame #{random_frame_number}')\n",
                "\n",
                "# Liberamos el recurso del video\n",
                "cap.release()\n",
                "print('\\nAnálisis de propiedades completado')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Recorte del video a una región de interés (ROI)\n",
                "\n",
                "Recortamos el video a una región de interés específica para enfocarnos en el área relevante del experimento.\n",
                "Esto reduce el tiempo de procesamiento y mejora la precisión del análisis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Definimos la región de interés (ROI) para recortar el video\n",
                "roi_x = 30      # Coordenada X inicial\n",
                "roi_y = 70      # Coordenada Y inicial\n",
                "roi_w = 520     # Ancho de la región\n",
                "roi_h = 245     # Alto de la región\n",
                "\n",
                "# Rutas de los archivos\n",
                "video_path = 'experiments/A-7.mp4'\n",
                "video_out = 'experiments/A-7_crop.mp4'\n",
                "\n",
                "print(f'Recortando video: {video_path}')\n",
                "print(f'Región de interés: x={roi_x}, y={roi_y}, ancho={roi_w}, alto={roi_h}')\n",
                "\n",
                "# Abrimos el video de entrada\n",
                "cap = cv2.VideoCapture(video_path)\n",
                "if not cap.isOpened():\n",
                "    print('ERROR: Error al abrir el video')\n",
                "    sys.exit(1)\n",
                "\n",
                "# Obtenemos las propiedades del video original\n",
                "fps = cap.get(cv2.CAP_PROP_FPS)\n",
                "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
                "\n",
                "print(f'Video original: {frame_count} frames a {fps} FPS')\n",
                "\n",
                "# Configuramos el codec para el video de salida\n",
                "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
                "\n",
                "# Creamos el escritor de video con las dimensiones del ROI\n",
                "out = cv2.VideoWriter(video_out, fourcc, fps, (roi_w, roi_h))\n",
                "\n",
                "# Procesamos cada frame del video\n",
                "print(f'Procesando frames...')\n",
                "frame_num = 0\n",
                "\n",
                "while True:\n",
                "    # Leemos el siguiente frame\n",
                "    ret, frame = cap.read()\n",
                "    \n",
                "    # Si no hay más frames, terminamos\n",
                "    if not ret:\n",
                "        break\n",
                "    \n",
                "    # Recortamos el frame a la región de interés\n",
                "    roi_frame = frame[roi_y:roi_y+roi_h, roi_x:roi_x+roi_w]\n",
                "    \n",
                "    # Guardamos el frame recortado\n",
                "    out.write(roi_frame)\n",
                "    \n",
                "    # Incrementamos el contador\n",
                "    frame_num += 1\n",
                "    \n",
                "    # Mostramos progreso cada 100 frames\n",
                "    if frame_num % 100 == 0:\n",
                "        print(f'  Procesados {frame_num}/{frame_count} frames...')\n",
                "\n",
                "# Liberamos los recursos\n",
                "cap.release()\n",
                "out.release()\n",
                "\n",
                "print(f'\\nVideo recortado guardado exitosamente')\n",
                "print(f'  Archivo: {video_out}')\n",
                "print(f'  Frames procesados: {frame_num}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Análisis del video con DeepLabCut\n",
                "\n",
                "Ejecutamos el análisis del video recortado utilizando DeepLabCut para detectar y rastrear los puntos clave del animal."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ruta al video que vamos a analizar\n",
                "video_anal = 'experiments/A-7_crop.mp4'\n",
                "\n",
                "print(f'Iniciando análisis con DeepLabCut...')\n",
                "print(f'Video: {video_anal}')\n",
                "\n",
                "# Registramos el tiempo de inicio\n",
                "start_time = time.time()\n",
                "\n",
                "# Ejecutamos el análisis con DeepLabCut\n",
                "# Este proceso identifica y rastrea los puntos clave del animal en cada frame\n",
                "dlc.analyze_videos(\n",
                "    path_config_file,\n",
                "    [video_anal],\n",
                "    videotype='mp4',\n",
                "    shuffle=1,\n",
                "    trainingsetindex=0,\n",
                "    gputouse=None,\n",
                "    save_as_csv=True\n",
                ")\n",
                "\n",
                "# Calculamos el tiempo transcurrido\n",
                "elapsed_time = time.time() - start_time\n",
                "minutes = elapsed_time / 60\n",
                "\n",
                "print(f'\\nAnálisis completado exitosamente')\n",
                "print(f'  Tiempo: {elapsed_time:.2f} segundos ({minutes:.2f} minutos)')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Filtrado de predicciones\n",
                "\n",
                "Aplicamos un filtro ARIMA a las predicciones para suavizar las trayectorias y reducir el ruido en los datos de seguimiento."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('Aplicando filtro ARIMA a las predicciones...')\n",
                "print('Este filtro suaviza las trayectorias y reduce el ruido en los datos')\n",
                "\n",
                "# Parámetros del filtro ARIMA\n",
                "window_length = 5    # Tamaño de la ventana temporal\n",
                "ar_degree = 3        # Grado del componente autoregresivo\n",
                "ma_degree = 1        # Grado del componente de media móvil\n",
                "p_bound = 0.7        # Umbral de probabilidad\n",
                "alpha = 0.01         # Nivel de significancia\n",
                "\n",
                "# Aplicamos el filtro a las predicciones\n",
                "dlc.filterpredictions(\n",
                "    path_config_file,\n",
                "    [video_anal],\n",
                "    shuffle=1,\n",
                "    trainingsetindex=0,\n",
                "    filtertype='arima',\n",
                "    windowlength=window_length,\n",
                "    p_bound=p_bound,\n",
                "    ARdegree=ar_degree,\n",
                "    MAdegree=ma_degree,\n",
                "    alpha=alpha,\n",
                "    save_as_csv=True,\n",
                "    destfolder=None,\n",
                "    modelprefix='',\n",
                "    track_method='',\n",
                "    return_data=False\n",
                ")\n",
                "\n",
                "print('Filtrado completado exitosamente')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Creación de video con etiquetas\n",
                "\n",
                "Generamos un video con las predicciones superpuestas para visualizar los resultados del seguimiento.\n",
                "\n",
                "Nota: Ajuste la ruta `output_video` según su sistema antes de ejecutar esta celda."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ruta al video que queremos etiquetar con las predicciones\n",
                "output_video = 'experiments/A-7_crop.mp4'\n",
                "\n",
                "print(f'Creando video etiquetado...')\n",
                "print(f'Video de entrada: {output_video}')\n",
                "\n",
                "# Creamos el video con las etiquetas y puntos clave marcados\n",
                "# Este video muestra visualmente los resultados del análisis\n",
                "dlc.create_labeled_video(\n",
                "    path_config_file,\n",
                "    [output_video],\n",
                "    shuffle=1,\n",
                "    trainingsetindex=0,\n",
                "    filtered=False,\n",
                "    save_frames=False,\n",
                "    displayedbodyparts='all',\n",
                "    draw_skeleton=False,\n",
                "    trailpoints=0,\n",
                "    videotype='mp4'\n",
                ")\n",
                "\n",
                "print('\\nVideo etiquetado creado exitosamente')\n",
                "print('  El video estará en la misma carpeta con el sufijo \"_labeled\"')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "dlc",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}